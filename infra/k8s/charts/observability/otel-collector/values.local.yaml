mode: deployment

replicaCount: 1

image:
  repository: otel/opentelemetry-collector-contrib

service:
  type: NodePort

# Required for k8sattributes processor (enrich telemetry with k8s metadata).
serviceAccount:
  create: true
  name: otel-collector
  automountServiceAccountToken: true

clusterRole:
  create: true
  clusterRoleBinding: {}
  rules:
    - apiGroups: [""]
      resources: ["pods", "namespaces", "nodes"]
      verbs: ["get", "list", "watch"]

ports:
  otlp:
    enabled: true
    containerPort: 4317
    servicePort: 4317
    protocol: TCP

  otlp-http:
    enabled: true
    containerPort: 4318
    servicePort: 4318
    protocol: TCP

  metrics:
    enabled: true
    containerPort: 8889
    servicePort: 8889
    protocol: TCP

serviceMonitor:
  enabled: true
  extraLabels :
    release: prometheus
  metricsEndpoints:
    - port: metrics
      interval: 15s

config:
  receivers:
    otlp:
      protocols:
        grpc: {}
        http: {}

  extensions:
    health_check: {}

  processors:
    memory_limiter:
      check_interval: 5s
      limit_mib: 400
      spike_limit_mib: 100

    batch:
      timeout: 5s
      send_batch_size: 1024

    resource:
      attributes:
        - key: "deployment.environment"
          value: local
          action: insert

    # Adds k8s.namespace.name, k8s.pod.name, etc. based on the incoming connection/pod IP.
    # This makes our Tempo tracesToMetrics queries (and logsâ†’metrics links) viable.
    k8sattributes:
      auth_type: serviceAccount
      passthrough: false
      extract:
        metadata:
          - k8s.namespace.name
          - k8s.pod.name
          - k8s.node.name

    # Derive a millisecond epoch timestamp for Grafana URL time params.
    # Grafana Loki derivedFields reliably expose only `${__value.raw}`, so we need the
    # matched value to already be in epoch-ms.
    transform/log_links:
      error_mode: ignore
      log_statements:
        - set(log.attributes["observed_timestamp_ms"], Int(log.observed_time_unix_nano / 1000000)) where log.observed_time_unix_nano != nil
        - set(log.attributes["observed_timestamp"], String(log.observed_time_unix_nano)) where log.observed_time_unix_nano != nil and log.attributes["observed_timestamp"] == nil
        - set(log.attributes["k8s_pod_name"], resource.attributes["k8s.pod.name"]) where log.attributes["k8s_pod_name"] == nil and resource.attributes["k8s.pod.name"] != nil
        - set(log.attributes["grafana_link_params"], Format("var-ts=%d&var-pod=%s&time=%d", [log.observed_time_unix_nano, log.attributes["k8s_pod_name"], Int(log.observed_time_unix_nano / 1000000)])) where log.observed_time_unix_nano != nil and log.attributes["k8s_pod_name"] != nil

  exporters:
    otlp/tempo:
      endpoint: tempo-distributor.observability.svc.cluster.local:4317
      tls:
        insecure: true

    prometheus:
      endpoint: "0.0.0.0:8889"
      resource_to_telemetry_conversion:
        enabled: true

  service:
    extensions: [health_check]
    pipelines:
      traces:
        receivers: [otlp]
        processors: [memory_limiter, resource, k8sattributes, batch]
        exporters: [otlp/tempo]

      logs:
        receivers: [otlp]
        processors: [memory_limiter, resource, k8sattributes, transform/log_links, batch]
        exporters: [otlphttp/loki]

      metrics:
        receivers: [otlp]
        processors: [memory_limiter, resource, k8sattributes, batch]
        exporters: [prometheus]
